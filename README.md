# Visual exploration for explaining image classification
A working demo can be found [here](https://ethanzyn.github.io/AI_explainability) and here is a short video explaining the different featues of the visualization, 

<a href="https://youtu.be/lkqLJnafMbg" target="_blank"><img src="../master/video_screenshot.JPG" width="450" alt="project video"/></a>

Pretrained gender and emotion classification models borrowed from [here](https://github.com/oarriaga/face_classification). The explanation engine used for generating model explanation is [LIME](https://github.com/marcotcr/lime).

Dataset: A sample of 1000 celebA images stored in the Dataset folder. The complete dataset can be found [here](https://www.kaggle.com/jessicali9530/celeba-dataset).

The source code for classification and explanation generation using LIME is located in [gender_emotion_model.ipynb](../master/face_classification/src/gender_emotion_model.ipynb)

